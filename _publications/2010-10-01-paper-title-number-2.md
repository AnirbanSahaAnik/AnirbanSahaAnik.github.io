---
title: "Multi-Agent Retrieval-Augmented Framework for Evidence-Based Counterspeech Against Health Misinformation"
collection: publications
category: conferences
permalink: /publication/2025-colm-multiagent-counterspeech
excerpt: 'We present a multi-agent LLM framework for generating evidence-based counterspeech grounded in dynamic and static retrieval sources.'
date: 2025-03-21
venue: 'Conference on Language Models (COLM 2025) – Accepted'
paperurl: 'https://arxiv.org/abs/2507.07307'  # Add PDF link here when available
citation: 'Anirban Saha Anik, Xiaoying Song, Elliott Wang, Bryan Wang, Bengisu Yarimbas, Lingzi Hong. (2025). "Multi-Agent Retrieval-Augmented Framework for Evidence-Based Counterspeech Against Health Misinformation." <i>Conference on Language Models (COLM 2025)</i>.'
---

**Abstract**  
Large language models (LLMs) integrated with Retrieval-Augmented Generation (RAG) have shown strong potential in generating counterspeech against misinformation. However, existing methods often rely on limited evidence and offer minimal control over generated responses.

To overcome these limitations, we propose a **Multi-Agent Retrieval-Augmented Framework** for generating evidence-based counterspeech targeting health misinformation. This framework coordinates multiple LLM agents responsible for evidence retrieval, summarization, generation, and refinement. By integrating both static and dynamic sources, the framework ensures that responses are timely, well-supported, and contextually appropriate.

Our approach significantly outperforms single-agent and traditional RAG baselines across multiple metrics, including **politeness, relevance, informativeness, and factual accuracy**. Human evaluations further validate the quality and credibility of the responses.

**Keywords**: Large Language Models, Multi-Agent Systems, Retrieval-Augmented Generation, Health Misinformation, Counterspeech

---

### Method Overview

![Figure 1: Multi-Agent Counterspeech Framework](\images\Paper-2\marf_page-0001.jpg)

**Figure 1**: Overview of our proposed Multi-Agent Counterspeech Generation Framework for addressing health misinformation.  
- The **Static Retrieval Agent** collects background evidence from trusted offline sources.  
- The **Dynamic Retrieval Agent** fetches real-time web content using DuckDuckGo search.  
- The **Summarization Agent** ranks and filters combined evidence for clarity and relevance.  
- The **Counterspeech Generation Agent** produces a response grounded in the summarized evidence.
- Finally, the **Refinement Agent** polishes the response to enhance clarity, politeness, and factual accuracy.
This modular architecture promotes transparency and adaptability, ensuring that counterspeech remains respectful and evidence-based even in rapidly evolving misinformation scenarios.

---

### Experimental Results

![Figure 2: Evaluation Results](\images\Paper-2\bar_chart_with_std_page-0001.jpg)

**Figure 2**: Performance comparison of different counterspeech generation approaches across four evaluation metrics — **Politeness**, **Relevance**, **Informativeness**, and **Factual Accuracy**.  
The **Multi-Agent** framework consistently outperforms baselines, including static and dynamic RAG setups and prompting-only methods. Error bars indicate standard deviation across annotators.

---

### Key Findings

- **Politeness and Trustworthiness**: The multi-agent pipeline produces responses that are more respectful and user-aligned, crucial in high-stakes domains like health.
- **Factual Grounding**: Dynamic evidence combined with trusted static sources leads to higher factual accuracy.
- **Modular Design**: Ablation studies show that removing any agent (e.g., summarization or refinement) degrades performance, underscoring the importance of each module.
- **Human Preference**: Human evaluators consistently prefer the responses generated by the multi-agent system over those from baseline models.

---

### BibTeX

```bibtex
@inproceedings{anik2025multiagent,
  title={Multi-Agent Retrieval-Augmented Framework for Evidence-Based Counterspeech Against Health Misinformation},
  author={Anirban Saha Anik and Xiaoying Song and Elliott Wang and Bryan Wang and Bengisu Yarimbas and Lingzi Hong},
  booktitle={Proceedings of the Second Conference on Language Modeling (COLM)},
  year={2025},
  url={https://openreview.net/forum?id=P61AgRyU7E}
}

